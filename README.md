# CUDA-Accelerated K-Means Clustering

An optimized K-Means implementation leveraging NVIDIA GPUs. It features CUDA-accelerated **k-means++** initialization, **triangle-inequality** pruning (Elkan/Hamerly), **multi-stream** overlap of compute and transfer, and **batched** execution to scale beyond GPU memory. Data is stored in **Structure-of-Arrays (SoA)** layout for coalesced memory access, and **CSR graph representation** is used for sparse data handling.

<p align="center">
  <img src="https://img.shields.io/badge/CUDA-11%2B-76B900.svg"/> 
  <img src="https://img.shields.io/badge/CMake-3.20%2B-blue.svg"/> 
  <img src="https://img.shields.io/badge/License-MIT-lightgrey.svg"/>
</p>

---

## Why this project?

Classical K-Means is simple but memory-bound and distance-heavy. On modern GPUs, we can push it much further by:

- Parallelizing distance and centroid updates with custom CUDA kernels  
- Seeding with **k-means++** on GPU to reduce iterations  
- Cutting redundant distance evaluations with **Elkan/Hamerly** bounds  
- Overlapping hostâ†”device transfers with compute using **multiple CUDA streams**  
- **Batching** datasets that donâ€™t fit in device RAM (GPU memory).  
- Using **CSR graph representation** to efficiently handle sparse datasets

### Quantified results

- **Latency hiding:** Overlapping compute and memcpy hides ~**40%** of H2D/D2H time on PCIe.
- **Fewer distance computations:** Elkan/Hamerly pruning eliminates more than **50%** of distance evaluations after 2â€“3 iterations.

## Key Features

- âš¡ **GPU Acceleration:** CUDA kernels for distance calculations and centroid updates  
- ðŸŽ¯ **k-means++ Initialization:** GPU-parallelized seeding  
- ðŸ§® **Triangle-Inequality Pruning:** Elkan & Hamerly methods  
- ðŸ” **Multi-Stream Overlap:** multiple CUDA streams hide ~40% transfer latency  
- ðŸ“¦ **Batched Processing:** Works with datasets > GPU memory  
- ðŸ§± **SoA Layout:** Coalesced reads/writes for better memory throughput  
- ðŸ—œ **CSR Graph Representation:** Sparse datasets stored and processed efficiently

---

## Directory Structure

```
.
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ kmeans.hpp
â”‚   â”œâ”€â”€ device_utils.cuh
â”‚   â”œâ”€â”€ bounds.cuh
â”‚   â””â”€â”€ init_kmeanspp.cuh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ kmeans.cu
â”‚   â”œâ”€â”€ init_kmeanspp.cu
â”‚   â”œâ”€â”€ bounds.cu
â”‚   â”œâ”€â”€ batching.cu
â”‚   â””â”€â”€ kmeans_cpu_ref.cpp
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ kmeans_cli.cpp
â”‚   â””â”€â”€ bench_kmeans.cpp
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (sample datasets)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ presentation.pdf
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ gen_data.py
â”‚   â””â”€â”€ reproduce_bench.sh
â””â”€â”€ tests/
    â””â”€â”€ test_kmeans.cpp
```
## Implementation Notes

- **SoA layout** ensures coalesced memory access  
- **CSR graph representation** is used to store sparse datasets, reducing memory footprint and speeding up distance computations by skipping zero entries  
- **k-means++** uses parallel prefix sums for better initial cluster selection  
- **Elkan/Hamerly bounds** reduce distance checks significantly  
- **Multi-stream pipelining** overlaps compute and transfers for 40% latency reduction

---

## Contributing

Pull requests welcome! Key focus areas:
  -  Optimize kernel memory access patterns
  -  Add sparse suppport
  -  Implement half-precision mode.


## Acknowledgements

- Elkan, C. (2003) "Using the Triangle Inequality to Accelerate k-Means"
- Hamerly, G. (2010) "Making k-Means Even Faster"
- NVIDIA Nsight for profiling
